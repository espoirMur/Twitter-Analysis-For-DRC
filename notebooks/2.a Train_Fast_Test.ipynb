{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train our model on the fast test on our tweetts to learn words  embeddings , "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why fastext and not other embedding techics ? \n",
    "\n",
    "Popular word emdedding are learn the vector representation of words by assigning a distinct vector to each word this has limitation becauses some languages with distinct word , Facebook research suggested another appraoch by training a model using skip gramms where each word is represented by a bag of n grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model to lear the representation of the word __where__ they use the following n-grams to train the models : \n",
    "    <wh, whe, her, ere, re, where> . This appraochs seems to be appropriate for our corpus since it can be appropriate to capture misspelling characters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train the model on our tweets corpus and we will enrich our dataset with some wikipedia french article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So enough talking let go to the code ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainning the model on our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by training the model on our personnal tweets and see what we will get as the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es.py/Projects/Personal/nlp_course_coursera_russia_uni/.venv/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es.py/Projects/Personal/nlp_course_coursera_russia_uni/.venv/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/cleanned_tweets_2021.csv', index_col='id', parse_dates=['created_at'])[['created_at', 'cleanned_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.cleanned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = Path.cwd().parent.joinpath('data', 'tweets_corpus.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.dropna().to_csv(corpus_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = datapath(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/es.py/Projects/Personal/balobi_nini/data/tweets_corpus.cor'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since our topic use bigrams we can also learn bigrams but for th first try let us use the ngrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=64062, size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model_gensim = FT_gensim(size=50)\n",
    "\n",
    "# build the vocabulary\n",
    "model_gensim.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model_gensim.train(\n",
    "    corpus_file=corpus_file, \n",
    "    epochs=50,\n",
    "    window=4,\n",
    "    total_examples=model_gensim.corpus_count, total_words=model_gensim.corpus_total_words\n",
    ")\n",
    "\n",
    "print(model_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4553818"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let us now use the model to check some words \n",
    "print(\"felix\" in model_gensim.wv.vocab)\n",
    "print(\"tshisekedi\" in model_gensim.wv.vocab)\n",
    "model_gensim.wv.similarity(\"cuivre\", \"cobalt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('profelix', 0.8690589666366577),\n",
       " ('féli', 0.8555183410644531),\n",
       " ('félix', 0.833075225353241),\n",
       " ('félin', 0.7862865328788757),\n",
       " ('feli', 0.783075749874115),\n",
       " ('félixa', 0.7589821815490723),\n",
       " ('profélix', 0.7565920352935791),\n",
       " ('felixa', 0.7503924369812012),\n",
       " ('félixer', 0.7476751208305359),\n",
       " ('felik', 0.7120585441589355)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"felix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I can see in this that our modele just learn the morphlogical structure of word but does not take into account the context of the words . let see how to improve that by using another approach or by adding new training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('denisenyakeru', 0.9361186027526855),\n",
       " ('nyakeru', 0.7921234965324402),\n",
       " ('denissassounguesso', 0.7138336300849915),\n",
       " ('denis', 0.6725730299949646),\n",
       " ('deni', 0.6640692353248596),\n",
       " ('denie', 0.6558032631874084),\n",
       " ('denismukwege', 0.6381685733795166),\n",
       " ('distinguer', 0.6237839460372925),\n",
       " ('distingue', 0.6219795346260071),\n",
       " ('unpc', 0.6199365854263306)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar('denise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let me stop by here and go and look for the other dataset to use here \n",
    "\n",
    "if everything fails on saturday , i will use this \n",
    "\n",
    "https://towardsdatascience.com/word2vec-for-phrases-learning-embeddings-for-more-than-one-word-727b6cf723cf\n",
    "    \n",
    "https://stackoverflow.com/questions/55137013/parsing-incrementally-a-large-wikipedia-dump-xml-file-using-python\n",
    "    \n",
    "Or all the news from all the congolese medias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('qalf', 0.7105224132537842),\n",
       " ('dami', 0.5982264280319214),\n",
       " ('influenceur', 0.5794786214828491),\n",
       " ('dagen', 0.5636308789253235),\n",
       " ('dadju', 0.5620927214622498),\n",
       " ('musik', 0.5447028875350952),\n",
       " ('esporte', 0.5392625331878662),\n",
       " ('dammi', 0.5361876487731934),\n",
       " ('daron', 0.5305825471878052),\n",
       " ('werrason', 0.5262169241905212)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"damso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cobal', 0.9081646800041199),\n",
       " ('cobalto', 0.8831081986427307),\n",
       " ('cuivrecobalt', 0.8740710020065308),\n",
       " ('coppercobalt', 0.8410187363624573),\n",
       " ('kobalt', 0.8126835227012634),\n",
       " ('coba', 0.7666612863540649),\n",
       " ('cobaye', 0.7183268666267395),\n",
       " ('minerals', 0.7121819853782654),\n",
       " ('mine', 0.7020078897476196),\n",
       " ('childlabour', 0.6956951022148132)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"cobalt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6359072"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"coltant\", \"minerais\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11366845"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"argent\", \"or\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084563"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"katanga\", \"katumbi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ppr', 0.8317607045173645),\n",
       " ('fccpprd', 0.8194120526313782),\n",
       " ('fcc', 0.7430800795555115),\n",
       " ('udp', 0.7385269403457642),\n",
       " ('rdcpprd', 0.726458728313446),\n",
       " ('pprdfcc', 0.718801736831665),\n",
       " ('udps', 0.6936943531036377),\n",
       " ('ludp', 0.6687043905258179),\n",
       " ('néhémiemwilanya', 0.6614943742752075),\n",
       " ('kabuy', 0.6584582328796387)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"pprd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('josep', 0.8933290839195251),\n",
       " ('rdcjoseph', 0.8916415572166443),\n",
       " ('josephine', 0.8716621398925781),\n",
       " ('jeanjoseph', 0.8547133207321167),\n",
       " ('josephmobutu', 0.793563723564148),\n",
       " ('josephnsingaudjuu', 0.7783849239349365),\n",
       " ('joseh', 0.7679293751716614),\n",
       " ('josepholengankoy', 0.7624698877334595),\n",
       " ('jose', 0.7369823455810547),\n",
       " ('joséph', 0.7165120840072632)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"joseph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vitalkamerhe', 0.870186984539032),\n",
       " ('vitalk', 0.8529807925224304),\n",
       " ('vitalsunzu', 0.7590227723121643),\n",
       " ('kamerhe', 0.7363859415054321),\n",
       " ('vitamin', 0.7302271127700806),\n",
       " ('kamerhegate', 0.6838607788085938),\n",
       " ('vitalizi', 0.6816379427909851),\n",
       " ('vitamine', 0.6806851029396057),\n",
       " ('ital', 0.6514036059379578),\n",
       " ('pourvitaletfreddy', 0.6371611952781677)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"vital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('djammal', 0.9653528928756714),\n",
       " ('samihjammal', 0.929349422454834),\n",
       " ('sammyjammal', 0.9077848196029663),\n",
       " ('avocatsjammal', 0.8658848404884338),\n",
       " ('jammu', 0.7935233116149902),\n",
       " ('samih', 0.7775634527206421),\n",
       " ('jammel', 0.7261067032814026),\n",
       " ('jamal', 0.6532564163208008),\n",
       " ('jammeh', 0.6260073781013489),\n",
       " ('tuberculose', 0.6037260890007019)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"jammal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sami', 0.7634096741676331),\n",
       " ('sammy', 0.6754547357559204),\n",
       " ('samith', 0.6662032604217529),\n",
       " ('mibimba', 0.6508710384368896),\n",
       " ('sam', 0.6420586705207825),\n",
       " ('samesam', 0.6218844652175903),\n",
       " ('samih', 0.6187479496002197),\n",
       " ('samolot', 0.6159681081771851),\n",
       " ('cinquantaine', 0.6117323637008667),\n",
       " ('cabin', 0.6086095571517944)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"samibo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fayul', 0.9285195469856262),\n",
       " ('fayu', 0.9176452159881592),\n",
       " ('martinfayulu', 0.9175214767456055),\n",
       " ('fayululamuka', 0.891889750957489),\n",
       " ('fayulungoy', 0.8634165525436401),\n",
       " ('fauyulu', 0.8591745495796204),\n",
       " ('martin', 0.8283794522285461),\n",
       " ('casfayulumuzito', 0.8190137147903442),\n",
       " ('fayulist', 0.8101834058761597),\n",
       " ('tshisekedifayulu', 0.7213061451911926)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"fayulu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('covidvaccin', 0.929192066192627),\n",
       " ('covi', 0.900388240814209),\n",
       " ('coronavi', 0.8868720531463623),\n",
       " ('postcovid', 0.8855199217796326),\n",
       " ('coronaviru', 0.8792387843132019),\n",
       " ('coronav', 0.8769454956054688),\n",
       " ('coronavirus', 0.8745739459991455),\n",
       " ('precovid', 0.8507363200187683),\n",
       " ('cov', 0.8440157175064087),\n",
       " ('covidcall', 0.8278982043266296)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100jours', 0.9654565453529358),\n",
       " ('100jr', 0.7883129119873047),\n",
       " ('eiatoir', 0.6461061835289001),\n",
       " ('100jrs', 0.6457435488700867),\n",
       " ('jour', 0.634260892868042),\n",
       " ('tjour', 0.6267215609550476),\n",
       " ('courtrai', 0.6222000122070312),\n",
       " ('alourdir', 0.6076679825782776),\n",
       " ('indéniable', 0.6022735834121704),\n",
       " ('dépuis', 0.5943247079849243)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"100jour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3juge', 0.928546667098999),\n",
       " ('jugeprésid', 0.7677919268608093),\n",
       " ('jugentil', 0.738154411315918),\n",
       " ('affairejugescourconstitutionnell', 0.7351229786872864),\n",
       " ('rdccour', 0.7169229388237),\n",
       " ('rdccourconstitutionnell', 0.7082167267799377),\n",
       " ('investiturejugesconstitutionnel', 0.687548041343689),\n",
       " ('jugee', 0.6801027059555054),\n",
       " ('courconstitutionnelle', 0.6797974705696106),\n",
       " ('courconstitutionnell', 0.6775679588317871)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"juge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('marieolive', 0.8866996169090271),\n",
       " ('lembe', 0.8638077974319458),\n",
       " ('oliver', 0.8503016829490662),\n",
       " ('olivelem', 0.8159382343292236),\n",
       " ('olivelemb', 0.7933960556983948),\n",
       " ('lember', 0.7593467831611633),\n",
       " ('marieoliv', 0.7457270622253418),\n",
       " ('oliveirer', 0.7438076138496399),\n",
       " ('olivelembekabila', 0.6951661109924316),\n",
       " ('lemb', 0.6847491264343262)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"olive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ipup', 0.6978573203086853),\n",
       " ('fallen', 0.6814439296722412),\n",
       " ('fallyipuper', 0.6700296998023987),\n",
       " ('music', 0.668106198310852),\n",
       " ('fall', 0.6514086723327637),\n",
       " ('ipupa', 0.6331561207771301),\n",
       " ('falls', 0.6305659413337708),\n",
       " ('masterpiece', 0.6288599371910095),\n",
       " ('tist', 0.6280063986778259),\n",
       " ('museum', 0.6178829073905945)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"fally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('koffiolomid', 0.8536583781242371),\n",
       " ('koffiolomide', 0.8363623023033142),\n",
       " ('olomid', 0.8109546899795532),\n",
       " ('koffilisée', 0.8011969327926636),\n",
       " ('olomide', 0.7929778099060059),\n",
       " ('koffianan', 0.7812734842300415),\n",
       " ('kofi', 0.7045904397964478),\n",
       " ('olomider', 0.6150639653205872),\n",
       " ('koffa.eyrussur', 0.596304178237915),\n",
       " ('bobi', 0.5594942569732666)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"koffi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('virunganp', 0.9635626077651978),\n",
       " ('virunger', 0.9040197730064392),\n",
       " ('virungaorigin', 0.8939248323440552),\n",
       " ('virun', 0.850242018699646),\n",
       " ('ibirunga', 0.8469194769859314),\n",
       " ('virunganationalpark', 0.8272500038146973),\n",
       " ('kirunger', 0.8159387707710266),\n",
       " ('parc', 0.720731258392334),\n",
       " ('turunga', 0.7177234292030334),\n",
       " ('gorill', 0.6949065923690796)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"virunga\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wait this yied to better resutls than the others parameter from a human evaluation prespective, let me save the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd().parent.joinpath('models', 'embeddings_one_gram_fast_tweets_only').__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gensim.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fatshibéton', 0.854646623134613),\n",
       " ('fatshi.rien', 0.838394284248352),\n",
       " ('fatshiste', 0.8171983957290649),\n",
       " ('fatshist', 0.8025200963020325),\n",
       " ('fatshivit', 0.797540545463562),\n",
       " ('fatshiwalk', 0.7894046306610107),\n",
       " ('fatshister', 0.7874993681907654),\n",
       " ('fatshibee', 0.7715117335319519),\n",
       " ('fatshiguer', 0.7683554291725159),\n",
       " ('fatshikabila', 0.7610383629798889)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"fatshi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65631"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('felix', 'president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36092833"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('fatshi', 'president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50693405"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('tshisekedi', 'president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5341863"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('tshisekedi', 'antoine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4641587"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_gensim.wv.similarity(\"enquete\", \"inspection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rwander', 0.9001145958900452),\n",
       " ('rwand', 0.8864745497703552),\n",
       " ('rwandaer', 0.8850435614585876),\n",
       " ('rwandaugander', 0.8646469116210938),\n",
       " ('rwandauganda', 0.8578416705131531),\n",
       " ('rwan', 0.8455725312232971),\n",
       " ('rwandair', 0.8343261480331421),\n",
       " ('rwandaan', 0.8331326246261597),\n",
       " ('rwandophon', 0.8268706202507019),\n",
       " ('burundirdcrwander', 0.8225044012069702)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"rwanda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5878123"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"rwanda\", \"kagame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('profmuyembe', 0.9338556528091431),\n",
       " ('muyemb', 0.9208013415336609),\n",
       " ('muyembetamfum', 0.8794257044792175),\n",
       " ('muyembo', 0.8627848029136658),\n",
       " ('jacquesmuyembe', 0.8026634454727173),\n",
       " ('muyez', 0.7161343693733215),\n",
       " ('kayembe', 0.6002174019813538),\n",
       " ('tharcisse', 0.5901921987533569),\n",
       " ('munyangi', 0.5856882333755493),\n",
       " ('malal', 0.5802093744277954)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"muyembe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5251166"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"muyembe\", \"covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43719184"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"covid\", \"inrb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mikehammer', 0.9315186738967896),\n",
       " ('hamm', 0.7548325061798096),\n",
       " ('hummer', 0.7518390417098999),\n",
       " ('scammer', 0.7088600993156433),\n",
       " ('mike', 0.696308434009552),\n",
       " ('ambasser', 0.6619648337364197),\n",
       " ('interrog', 0.6496894359588623),\n",
       " ('affaireminembwe', 0.647415280342102),\n",
       " ('instammer', 0.6386048793792725),\n",
       " ('améri', 0.6355946063995361)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"hammer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('audite', 0.8729521036148071),\n",
       " ('auditorat', 0.8194636702537537),\n",
       " ('auditorium', 0.8154040575027466),\n",
       " ('dudit', 0.8036582469940186),\n",
       " ('érudit', 0.7982541918754578),\n",
       " ('auditors', 0.7865478992462158),\n",
       " ('auditer', 0.7834396362304688),\n",
       " ('auditor', 0.7793411612510681),\n",
       " ('auditoir', 0.7753593325614929),\n",
       " ('audition', 0.7088988423347473)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"audit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5784467"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"minerai\", \"coltan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5436104"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"minerai\", \"soussol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kibeni', 0.8113473057746887),\n",
       " ('beniadf', 0.809151828289032),\n",
       " ('benim', 0.8087350130081177),\n",
       " ('beniituriitombwemasisiwalikalerdc', 0.7742778062820435),\n",
       " ('benibutembo', 0.7695452570915222),\n",
       " ('beniiturimasisirdc', 0.7646398544311523),\n",
       " ('benirdc', 0.7496376037597656),\n",
       " ('benirnkrdc', 0.7265813946723938),\n",
       " ('ituri', 0.7237050533294678),\n",
       " ('benikangbayi', 0.7194468379020691)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"beni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beniadf', 0.8546262383460999),\n",
       " ('df', 0.7414668202400208),\n",
       " ('iscapadf', 0.7387275695800781),\n",
       " ('rdcadf', 0.7059139013290405),\n",
       " ('attaqu', 0.6856839656829834),\n",
       " ('djugu', 0.6841205358505249),\n",
       " ('djugurdc', 0.6712014079093933),\n",
       " ('beni', 0.6665497422218323),\n",
       " ('sdf', 0.6618329286575317),\n",
       " ('adfnalu', 0.6590484976768494)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"adf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665498"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"adf\", \"beni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('julienpaluku', 0.8972887992858887),\n",
       " ('baluku', 0.8018516898155212),\n",
       " ('maluku', 0.7823733687400818),\n",
       " ('julien', 0.6630211472511292),\n",
       " ('lukuni', 0.6235705614089966),\n",
       " ('vicepremier', 0.62265545129776),\n",
       " ('lusengo', 0.6155466437339783),\n",
       " ('formater', 0.6148018836975098),\n",
       " ('salukumb', 0.6085577607154846),\n",
       " ('matungulu', 0.5999795198440552)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"paluku\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5606126"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"ilunga\", \"premierministre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48577076"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"ilunga\", \"primature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-course-venv-v2",
   "language": "python",
   "name": "nlp-course-venv-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
