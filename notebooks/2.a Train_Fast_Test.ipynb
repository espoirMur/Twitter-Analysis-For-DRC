{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train our model on the fast test on our tweetts to learn words  embeddings , "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why fastext and not other embedding techics ? \n",
    "\n",
    "Popular word emdedding are learn the vector representation of words by assigning a distinct vector to each word this has limitation becauses some languages with distinct word , Facebook research suggested another appraoch by training a model using skip gramms where each word is represented by a bag of n grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model to lear the representation of the word __where__ they use the following n-grams to train the models : \n",
    "    <wh, whe, her, ere, re, where> . This appraochs seems to be appropriate for our corpus since it can be appropriate to capture misspelling characters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train the model on our tweets corpus and we will enrich our dataset with some wikipedia french article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So enough talking let go to the code ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainning the model on our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by training the model on our personnal tweets and see what we will get as the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es.py/Projects/Personal/nlp_course_coursera_russia_uni/.venv/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es.py/Projects/Personal/nlp_course_coursera_russia_uni/.venv/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/cleanned_tweets_2021.csv', index_col='id', parse_dates=['created_at'])[['created_at', 'cleanned_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.cleanned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = Path.cwd().parent.joinpath('data', 'tweets_corpus.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.dropna().to_csv(corpus_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = datapath(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/es.py/Projects/Personal/balobi_nini/data/tweets_corpus.cor'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since our topic use bigrams we can also learn bigrams but for th first try let us use the ngrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=64062, size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model_gensim = FT_gensim(size=50)\n",
    "\n",
    "# build the vocabulary\n",
    "model_gensim.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model_gensim.train(\n",
    "    corpus_file=corpus_file, \n",
    "    epochs=50,\n",
    "    window=4,\n",
    "    total_examples=model_gensim.corpus_count, total_words=model_gensim.corpus_total_words\n",
    ")\n",
    "\n",
    "print(model_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd().parent.joinpath('models', 'embeddings_one_gram_fast_tweets_only').__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gensim = FT_gensim.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4553818"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let us now use the model to check some words \n",
    "print(\"felix\" in model_gensim.wv.vocab)\n",
    "print(\"tshisekedi\" in model_gensim.wv.vocab)\n",
    "model_gensim.wv.similarity(\"cuivre\", \"cobalt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('profelix', 0.8690589666366577),\n",
       " ('féli', 0.8555183410644531),\n",
       " ('félix', 0.833075225353241),\n",
       " ('félin', 0.7862865328788757),\n",
       " ('feli', 0.783075749874115),\n",
       " ('félixa', 0.7589821815490723),\n",
       " ('profélix', 0.7565920352935791),\n",
       " ('felixa', 0.7503924369812012),\n",
       " ('félixer', 0.7476751208305359),\n",
       " ('felik', 0.7120585441589355)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"felix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I can see in this that our modele just learn the morphlogical structure of word but does not take into account the context of the words . let see how to improve that by using another approach or by adding new training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('denisenyakeru', 0.9361186027526855),\n",
       " ('nyakeru', 0.7921234965324402),\n",
       " ('denissassounguesso', 0.7138336300849915),\n",
       " ('denis', 0.6725730299949646),\n",
       " ('deni', 0.6640692353248596),\n",
       " ('denie', 0.6558032631874084),\n",
       " ('denismukwege', 0.6381685733795166),\n",
       " ('distinguer', 0.6237839460372925),\n",
       " ('distingue', 0.6219795346260071),\n",
       " ('unpc', 0.6199365854263306)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar('denise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let me stop by here and go and look for the other dataset to use here \n",
    "\n",
    "if everything fails on saturday , i will use this \n",
    "\n",
    "https://towardsdatascience.com/word2vec-for-phrases-learning-embeddings-for-more-than-one-word-727b6cf723cf\n",
    "    \n",
    "https://stackoverflow.com/questions/55137013/parsing-incrementally-a-large-wikipedia-dump-xml-file-using-python\n",
    "    \n",
    "Or all the news from all the congolese medias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('qalf', 0.7105224132537842),\n",
       " ('dami', 0.5982264280319214),\n",
       " ('influenceur', 0.5794786214828491),\n",
       " ('dagen', 0.5636308789253235),\n",
       " ('dadju', 0.5620927214622498),\n",
       " ('musik', 0.5447028875350952),\n",
       " ('esporte', 0.5392625331878662),\n",
       " ('dammi', 0.5361876487731934),\n",
       " ('daron', 0.5305825471878052),\n",
       " ('werrason', 0.5262169241905212)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"damso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cobal', 0.9081646800041199),\n",
       " ('cobalto', 0.8831081986427307),\n",
       " ('cuivrecobalt', 0.8740710020065308),\n",
       " ('coppercobalt', 0.8410187363624573),\n",
       " ('kobalt', 0.8126835227012634),\n",
       " ('coba', 0.7666612863540649),\n",
       " ('cobaye', 0.7183268666267395),\n",
       " ('minerals', 0.7121819853782654),\n",
       " ('mine', 0.7020078897476196),\n",
       " ('childlabour', 0.6956951022148132)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"cobalt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6359072"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"coltant\", \"minerais\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11366845"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"argent\", \"or\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084563"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"katanga\", \"katumbi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprd_similars_words = model_gensim.wv.most_similar(\"pprd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ppr', 0.8317607045173645),\n",
       " ('fccpprd', 0.8194120526313782),\n",
       " ('fcc', 0.7430800795555115),\n",
       " ('udp', 0.7385269403457642),\n",
       " ('rdcpprd', 0.726458728313446),\n",
       " ('pprdfcc', 0.718801736831665),\n",
       " ('udps', 0.6936943531036377),\n",
       " ('ludp', 0.6687043905258179),\n",
       " ('néhémiemwilanya', 0.6614943742752075),\n",
       " ('kabuy', 0.6584582328796387)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprd_similars_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_words_to_latex_table(word):\n",
    "    similars_words = model_gensim.wv.most_similar(word)\n",
    "    print(pd.DataFrame(data=similars_words, columns=['similar_words', 'distance']).to_latex(index=False, \n",
    "                                                                                       label=f'words_similar_to_{word}', \n",
    "                                                                                       caption=f'words similar to {word}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{words similar to covid}\n",
      "\\label{words_similar_to_covid}\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "similar\\_words &  distance \\\\\n",
      "\\midrule\n",
      "  covidvaccin &  0.929192 \\\\\n",
      "         covi &  0.900388 \\\\\n",
      "     coronavi &  0.886872 \\\\\n",
      "    postcovid &  0.885520 \\\\\n",
      "   coronaviru &  0.879239 \\\\\n",
      "      coronav &  0.876945 \\\\\n",
      "  coronavirus &  0.874574 \\\\\n",
      "     precovid &  0.850736 \\\\\n",
      "          cov &  0.844016 \\\\\n",
      "    covidcall &  0.827898 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similar_words_to_latex_table('covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('josep', 0.8933290839195251),\n",
       " ('rdcjoseph', 0.8916415572166443),\n",
       " ('josephine', 0.8716621398925781),\n",
       " ('jeanjoseph', 0.8547133207321167),\n",
       " ('josephmobutu', 0.793563723564148),\n",
       " ('josephnsingaudjuu', 0.7783849239349365),\n",
       " ('joseh', 0.7679293751716614),\n",
       " ('josepholengankoy', 0.7624698877334595),\n",
       " ('jose', 0.7369823455810547),\n",
       " ('joséph', 0.7165120840072632)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"joseph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vitalkamerhe', 0.870186984539032),\n",
       " ('vitalk', 0.8529807925224304),\n",
       " ('vitalsunzu', 0.7590227723121643),\n",
       " ('kamerhe', 0.7363859415054321),\n",
       " ('vitamin', 0.7302271127700806),\n",
       " ('kamerhegate', 0.6838607788085938),\n",
       " ('vitalizi', 0.6816379427909851),\n",
       " ('vitamine', 0.6806851029396057),\n",
       " ('ital', 0.6514036059379578),\n",
       " ('pourvitaletfreddy', 0.6371611952781677)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"vital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('djammal', 0.9653528928756714),\n",
       " ('samihjammal', 0.929349422454834),\n",
       " ('sammyjammal', 0.9077848196029663),\n",
       " ('avocatsjammal', 0.8658848404884338),\n",
       " ('jammu', 0.7935233116149902),\n",
       " ('samih', 0.7775634527206421),\n",
       " ('jammel', 0.7261067032814026),\n",
       " ('jamal', 0.6532564163208008),\n",
       " ('jammeh', 0.6260073781013489),\n",
       " ('tuberculose', 0.6037260890007019)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"jammal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sami', 0.7634096741676331),\n",
       " ('sammy', 0.6754547357559204),\n",
       " ('samith', 0.6662032604217529),\n",
       " ('mibimba', 0.6508710384368896),\n",
       " ('sam', 0.6420586705207825),\n",
       " ('samesam', 0.6218844652175903),\n",
       " ('samih', 0.6187479496002197),\n",
       " ('samolot', 0.6159681081771851),\n",
       " ('cinquantaine', 0.6117323637008667),\n",
       " ('cabin', 0.6086095571517944)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"samibo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fayul', 0.9285195469856262),\n",
       " ('fayu', 0.9176452159881592),\n",
       " ('martinfayulu', 0.9175214767456055),\n",
       " ('fayululamuka', 0.891889750957489),\n",
       " ('fayulungoy', 0.8634165525436401),\n",
       " ('fauyulu', 0.8591745495796204),\n",
       " ('martin', 0.8283794522285461),\n",
       " ('casfayulumuzito', 0.8190137147903442),\n",
       " ('fayulist', 0.8101834058761597),\n",
       " ('tshisekedifayulu', 0.7213061451911926)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"fayulu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('covidvaccin', 0.929192066192627),\n",
       " ('covi', 0.900388240814209),\n",
       " ('coronavi', 0.8868720531463623),\n",
       " ('postcovid', 0.8855199217796326),\n",
       " ('coronaviru', 0.8792387843132019),\n",
       " ('coronav', 0.8769454956054688),\n",
       " ('coronavirus', 0.8745739459991455),\n",
       " ('precovid', 0.8507363200187683),\n",
       " ('cov', 0.8440157175064087),\n",
       " ('covidcall', 0.8278982043266296)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100jours', 0.9654565453529358),\n",
       " ('100jr', 0.7883129119873047),\n",
       " ('eiatoir', 0.6461061835289001),\n",
       " ('100jrs', 0.6457435488700867),\n",
       " ('jour', 0.634260892868042),\n",
       " ('tjour', 0.6267215609550476),\n",
       " ('courtrai', 0.6222000122070312),\n",
       " ('alourdir', 0.6076679825782776),\n",
       " ('indéniable', 0.6022735834121704),\n",
       " ('dépuis', 0.5943247079849243)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"100jour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3juge', 0.928546667098999),\n",
       " ('jugeprésid', 0.7677919268608093),\n",
       " ('jugentil', 0.738154411315918),\n",
       " ('affairejugescourconstitutionnell', 0.7351229786872864),\n",
       " ('rdccour', 0.7169229388237),\n",
       " ('rdccourconstitutionnell', 0.7082167267799377),\n",
       " ('investiturejugesconstitutionnel', 0.687548041343689),\n",
       " ('jugee', 0.6801027059555054),\n",
       " ('courconstitutionnelle', 0.6797974705696106),\n",
       " ('courconstitutionnell', 0.6775679588317871)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"juge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_gensim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1db331858f94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_gensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"olive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_gensim' is not defined"
     ]
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"olive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ipup', 0.6978573203086853),\n",
       " ('fallen', 0.6814439296722412),\n",
       " ('fallyipuper', 0.6700296998023987),\n",
       " ('music', 0.668106198310852),\n",
       " ('fall', 0.6514086723327637),\n",
       " ('ipupa', 0.6331561207771301),\n",
       " ('falls', 0.6305659413337708),\n",
       " ('masterpiece', 0.6288599371910095),\n",
       " ('tist', 0.6280063986778259),\n",
       " ('museum', 0.6178829073905945)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"fally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('koffiolomid', 0.8536583781242371),\n",
       " ('koffiolomide', 0.8363623023033142),\n",
       " ('olomid', 0.8109546899795532),\n",
       " ('koffilisée', 0.8011969327926636),\n",
       " ('olomide', 0.7929778099060059),\n",
       " ('koffianan', 0.7812734842300415),\n",
       " ('kofi', 0.7045904397964478),\n",
       " ('olomider', 0.6150639653205872),\n",
       " ('koffa.eyrussur', 0.596304178237915),\n",
       " ('bobi', 0.5594942569732666)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"koffi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{words similar to beni}\n",
      "\\label{words_similar_to_beni}\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "                     similar\\_words &  distance \\\\\n",
      "\\midrule\n",
      "                            kibeni &  0.811347 \\\\\n",
      "                           beniadf &  0.809152 \\\\\n",
      "                             benim &  0.808735 \\\\\n",
      " beniituriitombwemasisiwalikalerdc &  0.774278 \\\\\n",
      "                       benibutembo &  0.769545 \\\\\n",
      "                beniiturimasisirdc &  0.764640 \\\\\n",
      "                           benirdc &  0.749638 \\\\\n",
      "                        benirnkrdc &  0.726581 \\\\\n",
      "                             ituri &  0.723705 \\\\\n",
      "                      benikangbayi &  0.719447 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similar_words_to_latex_table('beni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wait this yied to better resutls than the others parameter from a human evaluation prespective, let me save the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/es.py/Projects/Personal/balobi_nini/models/embeddings_one_gram_fast_tweets_only\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gensim.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fatshibéton', 0.854646623134613),\n",
       " ('fatshi.rien', 0.838394284248352),\n",
       " ('fatshiste', 0.8171983957290649),\n",
       " ('fatshist', 0.8025200963020325),\n",
       " ('fatshivit', 0.797540545463562),\n",
       " ('fatshiwalk', 0.7894046306610107),\n",
       " ('fatshister', 0.7874993681907654),\n",
       " ('fatshibee', 0.7715117335319519),\n",
       " ('fatshiguer', 0.7683554291725159),\n",
       " ('fatshikabila', 0.7610383629798889)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"fatshi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65631"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('felix', 'president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36092833"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('fatshi', 'president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50693405"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('tshisekedi', 'president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5341863"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('tshisekedi', 'antoine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4641587"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_gensim.wv.similarity(\"enquete\", \"inspection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rwander', 0.9001145958900452),\n",
       " ('rwand', 0.8864745497703552),\n",
       " ('rwandaer', 0.8850435614585876),\n",
       " ('rwandaugander', 0.8646469116210938),\n",
       " ('rwandauganda', 0.8578416705131531),\n",
       " ('rwan', 0.8455725312232971),\n",
       " ('rwandair', 0.8343261480331421),\n",
       " ('rwandaan', 0.8331326246261597),\n",
       " ('rwandophon', 0.8268706202507019),\n",
       " ('burundirdcrwander', 0.8225044012069702)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"rwanda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5878123"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"rwanda\", \"kagame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kangi', 0.7428670525550842),\n",
       " ('munyambo', 0.7159361839294434),\n",
       " ('jérôme', 0.7156420946121216),\n",
       " ('munyampenda', 0.7039382457733154),\n",
       " ('muny', 0.6835290789604187),\n",
       " ('jerôme', 0.683452844619751),\n",
       " ('kokonyangi', 0.682059109210968),\n",
       " ('ngoker', 0.676612913608551),\n",
       " ('nyanga', 0.6758219003677368),\n",
       " ('pangi', 0.6612526178359985)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"munyangi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5251166"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"muyembe\", \"covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43719184"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"covid\", \"inrb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mikehammer', 0.9315186738967896),\n",
       " ('hamm', 0.7548325061798096),\n",
       " ('hummer', 0.7518390417098999),\n",
       " ('scammer', 0.7088600993156433),\n",
       " ('mike', 0.696308434009552),\n",
       " ('ambasser', 0.6619648337364197),\n",
       " ('interrog', 0.6496894359588623),\n",
       " ('affaireminembwe', 0.647415280342102),\n",
       " ('instammer', 0.6386048793792725),\n",
       " ('améri', 0.6355946063995361)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"hammer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lekkimassacre', 0.9484295845031738),\n",
       " ('rdcmassacre', 0.9024498462677002),\n",
       " ('massacrer', 0.8962162733078003),\n",
       " ('stopauxmassacre', 0.8920787572860718),\n",
       " ('massacr', 0.8892701268196106),\n",
       " ('massacro', 0.8839914202690125),\n",
       " ('massacreur', 0.8694459199905396),\n",
       " ('massac', 0.8583980798721313),\n",
       " ('massacré', 0.8516150712966919),\n",
       " ('massacredeyumbi', 0.8285055756568909)]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"massacre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47173166"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"massacre\", \"beni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5436104"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"minerai\", \"soussol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kibeni', 0.8113473057746887),\n",
       " ('beniadf', 0.809151828289032),\n",
       " ('benim', 0.8087350130081177),\n",
       " ('beniituriitombwemasisiwalikalerdc', 0.7742778062820435),\n",
       " ('benibutembo', 0.7695452570915222),\n",
       " ('beniiturimasisirdc', 0.7646398544311523),\n",
       " ('benirdc', 0.7496376037597656),\n",
       " ('benirnkrdc', 0.7265813946723938),\n",
       " ('ituri', 0.7237050533294678),\n",
       " ('benikangbayi', 0.7194468379020691)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"beni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beniadf', 0.8546262383460999),\n",
       " ('df', 0.7414668202400208),\n",
       " ('iscapadf', 0.7387275695800781),\n",
       " ('rdcadf', 0.7059139013290405),\n",
       " ('attaqu', 0.6856839656829834),\n",
       " ('djugu', 0.6841205358505249),\n",
       " ('djugurdc', 0.6712014079093933),\n",
       " ('beni', 0.6665497422218323),\n",
       " ('sdf', 0.6618329286575317),\n",
       " ('adfnalu', 0.6590484976768494)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"adf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665498"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"adf\", \"beni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('julienpaluku', 0.8972887992858887),\n",
       " ('baluku', 0.8018516898155212),\n",
       " ('maluku', 0.7823733687400818),\n",
       " ('julien', 0.6630211472511292),\n",
       " ('lukuni', 0.6235705614089966),\n",
       " ('vicepremier', 0.62265545129776),\n",
       " ('lusengo', 0.6155466437339783),\n",
       " ('formater', 0.6148018836975098),\n",
       " ('salukumb', 0.6085577607154846),\n",
       " ('matungulu', 0.5999795198440552)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar(\"paluku\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5606126"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"ilunga\", \"premierministre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48577076"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(\"ilunga\", \"primature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ogefrem', 0.8979642987251282),\n",
       " ('ogefremter', 0.8116137981414795),\n",
       " ('sayiba', 0.6828110218048096),\n",
       " ('patientsayiba', 0.6793594360351562),\n",
       " ('irem', 0.6711934208869934),\n",
       " ('trem', 0.6703653931617737),\n",
       " ('sayiber', 0.65450519323349),\n",
       " ('aprem', 0.6284794211387634),\n",
       " ('rem', 0.621857762336731),\n",
       " ('cabinet', 0.6138765215873718)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar('ogfrem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kibeni', 0.8113473057746887),\n",
       " ('beniadf', 0.809151828289032),\n",
       " ('benim', 0.8087350130081177),\n",
       " ('beniituriitombwemasisiwalikalerdc', 0.7742778062820435),\n",
       " ('benibutembo', 0.7695452570915222),\n",
       " ('beniiturimasisirdc', 0.7646398544311523),\n",
       " ('benirdc', 0.7496376037597656),\n",
       " ('benirnkrdc', 0.7265813946723938),\n",
       " ('ituri', 0.7237050533294678),\n",
       " ('benikangbayi', 0.7194468379020691)]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar('beni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6717826"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('prison', 'makala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mukuna', 0.9030007719993591),\n",
       " ('tukunana', 0.8363571166992188),\n",
       " ('akuna', 0.7919146418571472),\n",
       " ('kuna', 0.760600745677948),\n",
       " ('mukuner', 0.7039006948471069),\n",
       " ('hakuna', 0.6964227557182312),\n",
       " ('amuna', 0.6068595051765442),\n",
       " ('muna', 0.6045168042182922),\n",
       " ('djuna', 0.6001457571983337),\n",
       " ('tisyamukuner', 0.5979771018028259)]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar('Mukuna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5240224"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('gombé', 'kinshasa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39409468"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('vitalkamerhe', 'jammal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using bi grams to learm words embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can use also bi grams to train embedding to learn bi grams representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = 'présidence cabinet chef cabinet conseiller spécial chef etat matir'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['présidence',\n",
       " 'cabinet',\n",
       " 'chef',\n",
       " 'cabinet',\n",
       " 'conseiller',\n",
       " 'spécial',\n",
       " 'chef',\n",
       " 'etat',\n",
       " 'matir']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram  = Phrases(sample_sentence, min_count=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(bigram.export_phrases(sample_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram   = Phrases(bigram[sample_sentence], min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim import models\n",
    "from gensim.utils import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.apply(lambda x : list(tokenize(x)) if type(x) == str else list(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['zambie', 'militaire', 'zambien', 'occuper', 'bout', 'territoire', 'diton', 'côté', 'fronti']),\n",
       "       list(['covid', 'essai', 'clinique', 'remède', 'curatif', 'bientôt', 'démarrer']),\n",
       "       list(['poursuivre', 'justice', 'val', 'mieux', 'contract', 'gre', 'gre', 'appel']),\n",
       "       ...,\n",
       "       list(['hop', 'fall', 'back', 'farmajo', 'need', 'accommodat', 'presidential', 'aspirer', 'need']),\n",
       "       list(['first', 'winner', 'tonight', 'sophi', 'doyl', 'inclusif', 'win', 'race', 'remington', 'park']),\n",
       "       list(['afrique', 'inauguration', 'consulat', 'revêtir', 'importance', 'politique', 'diplomatique', 'concréti', 'soutie'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ = corpus.values\n",
    "bigram = Phrases(token_, min_count=1, threshold=-.1,  delimiter=b'_', scoring='npmi')\n",
    "\n",
    "\n",
    "bigram_phraser = Phraser(bigram)\n",
    "\n",
    "bigram_token = []\n",
    "for sent in token_:\n",
    "    bigram_token.append(bigram_phraser[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214425"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['zambie_militaire',\n",
       "  'zambien_occuper',\n",
       "  'bout_territoire',\n",
       "  'diton_côté',\n",
       "  'fronti'],\n",
       " ['covid_essai', 'clinique_remède', 'curatif_bientôt', 'démarrer'],\n",
       " ['poursuivre_justice', 'val_mieux', 'contract_gre', 'gre_appel'],\n",
       " ['jemapeleeeeeee_madameeee',\n",
       "  'camp_fcc',\n",
       "  'bokola_koooooo',\n",
       "  'soni_lokola',\n",
       "  'ndumba'],\n",
       " ['fin_poursuite',\n",
       "  'judiciaire_procès',\n",
       "  'onem_accueillir',\n",
       "  'chômeur_vendre',\n",
       "  'ven'],\n",
       " ['passeport_côté', 'assurer_contrat', 'semlex_renouveler', 'décision_pri'],\n",
       " ['kinshaser'],\n",
       " ['nomination_proche',\n",
       "  'jeanmarc_kabundakabund',\n",
       "  'président_udp',\n",
       "  'inscrire_cadr'],\n",
       " ['finally_code',\n",
       "  'gplv_prediction',\n",
       "  'model_ll',\n",
       "  'model_fitted',\n",
       "  'package_data',\n",
       "  'obvious'],\n",
       " ['giorno_qualcuno',\n",
       "  'spiegherà_percher',\n",
       "  'nella_ment',\n",
       "  'bacater_del',\n",
       "  'libberista_padano',\n",
       "  'assistenzialismo_mentr',\n",
       "  'contributi'],\n",
       " ['merci_digne', 'fils_dévouement', 'bravo_docteur'],\n",
       " ['qualcuno_può',\n",
       "  'spiegarmi_percher',\n",
       "  'nella_ment',\n",
       "  'bacater_del',\n",
       "  'libberista_padano',\n",
       "  'assistenzialismo_mentr',\n",
       "  'contributi']]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_token[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have already splited our corpus into bi grams and n grams we can now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the new sentences embeddings and the cowboy vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of this we trained another model on using the sentence to vec model and we can now compare the generated data from the both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sent2vec import Sent2vecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd().parent.joinpath('models', 'embedding_fasttext_bi_grams_cobow-ngrams.bin').__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/es.py/Projects/Personal/balobi_nini/models/embedding_fasttext_bi_grams_cobow-ngrams.bin'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gensim_bigrams = Sent2vecModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gensim_bigrams.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let test the sentence embedding how they are similars with the singular words embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', 'embed_sentence', 'embed_sentences', 'embed_unigrams', 'get_emb_size', 'get_unigram_embeddings', 'get_vocabulary', 'load_model', 'release_shared_mem']\n"
     ]
    }
   ],
   "source": [
    "print(dir(Sent2vecModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embed_sentence() takes at least 1 positional argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-119ea81d077b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_gensim_bigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32msrc/sent2vec.pyx\u001b[0m in \u001b[0;36msent2vec.Sent2vecModel.embed_sentence\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: embed_sentence() takes at least 1 positional argument (0 given)"
     ]
    }
   ],
   "source": [
    "model_gensim_bigrams.embed_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_rappeur = model_gensim_bigrams.embed_sentence('rappeur damso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.503623  ,  2.5503347 ,  1.3936646 ,  2.7257903 ,  3.7647457 ,\n",
       "         1.2789905 , -1.5905387 , -2.2654262 ,  3.3577151 ,  0.7713281 ,\n",
       "         0.97878206, -3.1993232 , -3.0951376 ,  1.7591903 ,  0.9033402 ,\n",
       "         2.315887  ,  0.02481484, -2.062632  , -2.1039617 ,  0.21898356,\n",
       "         0.48964953,  3.8920846 ,  0.0211165 , -1.854273  ,  1.0073987 ,\n",
       "        -1.5828823 ,  2.715283  , -1.8912041 , -1.9560972 , -2.909595  ,\n",
       "        -0.6308982 , -6.0372295 , -2.621658  , -1.1085954 ,  2.9317381 ,\n",
       "         1.4363334 ,  6.895108  , -1.9273722 , -2.2983465 , -0.904801  ,\n",
       "         3.9599943 ,  2.1984584 , -1.7684263 ,  3.880658  ,  2.9497237 ,\n",
       "        -0.28692108, -0.1860286 ,  0.4271028 , -3.4710407 , -2.2113962 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_rappeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.503623  ,  2.5503347 ,  1.3936646 ,  2.7257903 ,  3.7647457 ,\n",
       "        1.2789905 , -1.5905387 , -2.2654262 ,  3.3577151 ,  0.7713281 ,\n",
       "        0.97878206, -3.1993232 , -3.0951376 ,  1.7591903 ,  0.9033402 ,\n",
       "        2.315887  ,  0.02481484, -2.062632  , -2.1039617 ,  0.21898356,\n",
       "        0.48964953,  3.8920846 ,  0.0211165 , -1.854273  ,  1.0073987 ,\n",
       "       -1.5828823 ,  2.715283  , -1.8912041 , -1.9560972 , -2.909595  ,\n",
       "       -0.6308982 , -6.0372295 , -2.621658  , -1.1085954 ,  2.9317381 ,\n",
       "        1.4363334 ,  6.895108  , -1.9273722 , -2.2983465 , -0.904801  ,\n",
       "        3.9599943 ,  2.1984584 , -1.7684263 ,  3.880658  ,  2.9497237 ,\n",
       "       -0.28692108, -0.1860286 ,  0.4271028 , -3.4710407 , -2.2113962 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model_gensim_bigrams.embed_unigrams(['rappeur', 'damso']), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1249654e+00,  3.0898073e+00,  1.7035110e+00,  9.1662616e-01,\n",
       "         4.2086287e+00,  9.7178876e-01, -9.1430664e-01,  9.3612874e-01,\n",
       "         2.1358778e+00,  3.0094269e-01,  1.5043042e+00, -2.1798360e+00,\n",
       "        -2.3337157e+00,  1.4494510e+00,  4.2270881e-01,  1.1749967e+00,\n",
       "        -2.4575329e+00, -2.0536575e+00, -1.7981907e+00, -1.2245303e-01,\n",
       "         6.5341645e-01,  1.1613151e+00,  2.5359860e-03, -7.7205825e-01,\n",
       "         3.2439651e+00, -1.8237097e+00,  2.0065863e+00, -1.1008533e+00,\n",
       "        -7.0928830e-01, -1.0772154e+00, -1.2990234e+00, -5.9738021e+00,\n",
       "        -2.7657685e-01, -1.1376368e+00,  3.0076575e+00,  6.6856068e-01,\n",
       "         6.0121698e+00,  2.8926620e-01, -1.0109086e+00, -1.0122863e+00,\n",
       "         1.0364248e+00,  1.6270013e+00, -9.2879611e-01,  3.6172981e+00,\n",
       "         2.9326024e+00,  1.0642569e+00, -2.4437156e+00, -1.5605071e+00,\n",
       "        -1.2797467e+00, -8.1491292e-01]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim_bigrams.embed_unigrams(['rappeur', 'damso']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from this we can see that the embedding of a bigram is only the mean of the all single words embedings , this mean we can use also this models to check if our data make sence on a human evaluation side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors, names = model_gensim_bigrams.get_unigram_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64064, 50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(index=names, data=vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let now save our model in a formats gensim can handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import to_utf8\n",
    "from smart_open import open as smart_open\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_path = Path.cwd().parent.joinpath('models', 'embedding_fasttext_bi_grams_cobow-ngrams_gensim.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word2vec_format(embedding_df, output_file, binary=True):\n",
    "    \"\"\"Store the input-hidden weight matrix in the same format used by the original\n",
    "    C word2vec-tool, for compatibility.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding_df : a matrix with the emebedding of all vectors\n",
    "    output_file : the file where we need to output our results\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    total_vec, vector_size = embeddings_df.shape\n",
    "    with smart_open(output_file, 'wb') as fout:\n",
    "        print(total_vec, vector_size)\n",
    "        fout.write(to_utf8(\"%s %s\\n\" % (total_vec, vector_size)))\n",
    "        # store in sorted order: most frequent words at the top\n",
    "        for word, row in embeddings_df.iterrows():\n",
    "            if binary:\n",
    "                row  = np.array(row)\n",
    "                word = str(word)\n",
    "                row = row.astype(np.float32)\n",
    "                fout.write(to_utf8(word) + b\" \" + row.tostring())\n",
    "            else:\n",
    "                fout.write(to_utf8(\"%s %s\\n\" % (word, ' '.join(repr(val) for val in row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64064 50\n"
     ]
    }
   ],
   "source": [
    "save_word2vec_format(embeddings_df, model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gensim_model_cobow = KeyedVectors.load_word2vec_format(model_output_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kabila', 0.7265638113021851),\n",
       " ('marionnette', 0.7192040681838989),\n",
       " ('féli', 0.7175667881965637),\n",
       " ('éphémère', 0.6830247640609741),\n",
       " ('felix', 0.66924649477005),\n",
       " ('kabilie', 0.6602067351341248),\n",
       " ('peuple', 0.6598754525184631),\n",
       " ('politiquement', 0.6499875783920288),\n",
       " ('fatshibéton', 0.6493622660636902),\n",
       " ('béton', 0.6453214883804321)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.most_similar('fatshi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37762877"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.similarity('gombé', 'kinshasa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61849374"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.similarity('prison', 'makala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beniadf', 0.756182849407196),\n",
       " ('benikangbayi', 0.7522435188293457),\n",
       " ('rdcbeni', 0.7468602657318115),\n",
       " ('benibutembo', 0.7296181917190552),\n",
       " ('ituri', 0.7289918661117554),\n",
       " ('adf', 0.6950790882110596),\n",
       " ('assaillant', 0.6909458041191101),\n",
       " ('kangbayi', 0.6889922022819519),\n",
       " ('benirnkrdc', 0.6701213717460632),\n",
       " ('benirdc', 0.6582370400428772)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.most_similar('beni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34004632"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.similarity(\"ilunga\", \"primature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3926379"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.similarity(\"ilunga\", \"premierministre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100jour', 0.9182929992675781),\n",
       " ('100jr', 0.616071343421936),\n",
       " ('rdcprocè', 0.5662071704864502),\n",
       " ('procès', 0.548157274723053),\n",
       " ('procè', 0.5463023781776428),\n",
       " ('defaveur', 0.5453490614891052),\n",
       " ('100k', 0.5397199392318726),\n",
       " ('procèd', 0.5377115607261658),\n",
       " ('100', 0.5296829342842102),\n",
       " ('indéniable', 0.5266932249069214)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.most_similar('100jours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3237181"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.similarity('fally', 'koffi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now for at least 10 words let compair the embeddings of the 2 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('denisenyakeru', 0.9361186027526855),\n",
       " ('nyakeru', 0.7921234965324402),\n",
       " ('denissassounguesso', 0.7138336300849915),\n",
       " ('denis', 0.6725730299949646),\n",
       " ('deni', 0.6640692353248596),\n",
       " ('denie', 0.6558032631874084),\n",
       " ('denismukwege', 0.6381685733795166),\n",
       " ('distinguer', 0.6237839460372925),\n",
       " ('distingue', 0.6219795346260071),\n",
       " ('unpc', 0.6199365854263306)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar('denise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('denisenyakeru', 0.7657488584518433),\n",
       " ('emb', 0.593925416469574),\n",
       " ('roya', 0.5721980929374695),\n",
       " ('dame', 0.5697656869888306),\n",
       " ('fondation', 0.5643427968025208),\n",
       " ('francophoni', 0.5525744557380676),\n",
       " ('galant', 0.5419038534164429),\n",
       " ('lukabuanger', 0.5311821699142456),\n",
       " ('maman', 0.5273846983909607),\n",
       " ('distingue', 0.5251399278640747)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.most_similar('denise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7921235"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('denise', 'nyakeru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75718045"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.similarity('mine', 'cobalt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49145254"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('minerais', 'argent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coronaviru', 0.895472526550293),\n",
       " ('coronavirus', 0.89470374584198),\n",
       " ('covidvaccin', 0.8291741609573364),\n",
       " ('coronavi', 0.816797137260437),\n",
       " ('coronavirusupdate', 0.8015884757041931),\n",
       " ('anticovid', 0.7943799495697021),\n",
       " ('coronav', 0.7805402874946594),\n",
       " ('coronavir', 0.7728807926177979),\n",
       " ('impact', 0.760310173034668),\n",
       " ('rdccoronaviru', 0.7549446225166321)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model_cobow.most_similar('covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('covidvaccin', 0.929192066192627),\n",
       " ('covi', 0.900388240814209),\n",
       " ('coronavi', 0.8868720531463623),\n",
       " ('postcovid', 0.8855199217796326),\n",
       " ('coronaviru', 0.8792387843132019),\n",
       " ('coronav', 0.8769454956054688),\n",
       " ('coronavirus', 0.8745739459991455),\n",
       " ('precovid', 0.8507363200187683),\n",
       " ('cov', 0.8440157175064087),\n",
       " ('covidcall', 0.8278982043266296)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar('covid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the few words I have I can see that the model train with fasttext is giving me better results than the one train with cobow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try this with the bigrams bi doing the mean of embedddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vector = np.mean([model_gensim.wv.get_vector('felix'),  model_gensim.wv.get_vector('tshisekedi')], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('felix', 0.8902652859687805),\n",
       " ('felixtshisekedi', 0.8751411437988281),\n",
       " ('félixtshisekedi', 0.87404465675354),\n",
       " ('félix', 0.8202601671218872),\n",
       " ('profelix', 0.818912148475647),\n",
       " ('félin', 0.8160699605941772),\n",
       " ('tshisekedirésident', 0.8025269508361816),\n",
       " ('féli', 0.7958161234855652),\n",
       " ('présidenttshisekedi', 0.7900027632713318),\n",
       " ('tshisekedikabila', 0.7754204273223877)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similar_by_vector(bigram_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.055707  ,  0.01133515, -0.02445187,  0.03998778,  0.00049961,\n",
       "        0.00021474, -0.01707494,  0.05419108, -0.01494774,  0.008418  ,\n",
       "        0.00095156, -0.01259983, -0.02554877, -0.02325878,  0.02353654,\n",
       "       -0.00125609, -0.01195581,  0.00268321,  0.00372202,  0.01425702,\n",
       "       -0.0378741 , -0.03042736,  0.00470991,  0.02776988, -0.02639213,\n",
       "       -0.01747896, -0.01492559,  0.00213787, -0.03325922,  0.02519025,\n",
       "       -0.0211328 ,  0.01028438, -0.01720367,  0.01038123, -0.01379913,\n",
       "       -0.02729871, -0.01330152, -0.01315912, -0.01812238, -0.00481328,\n",
       "        0.00217676, -0.03884697,  0.00298519, -0.00651423, -0.02587881,\n",
       "       -0.00953276,  0.05232179, -0.05079406, -0.00992901, -0.0024267 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity(bigram_vector, 'president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.8945975 , -5.2749887 , -5.5780444 ,  4.7474213 , -5.2821655 ,\n",
       "        0.11708105,  1.3446469 ,  3.6624813 , -4.196017  ,  2.7029028 ,\n",
       "        0.746982  , -0.97705555,  1.5807414 ,  1.3943481 , -4.2368255 ,\n",
       "       -5.539106  ,  2.9508073 ,  3.9492614 , -1.1153783 ,  0.19690055,\n",
       "        1.56007   ,  1.72054   ,  2.5993829 , -0.46884185, -5.8189554 ,\n",
       "       -0.35604233, -0.24752985, -1.8239082 , -4.73745   , -0.33703917,\n",
       "       -6.156808  ,  1.9459124 , -2.4653695 , -1.3212204 ,  2.67593   ,\n",
       "        2.2600834 , -2.1182442 ,  3.4490979 , -0.22683668,  0.7086997 ,\n",
       "       -1.1334974 , -1.5623055 ,  2.973078  ,  7.301217  , -0.22619778,\n",
       "        5.0030255 ,  1.292185  , -0.20498455,  3.331811  , -5.6974053 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9971442 , 0.9946518 , 1.0002204 , ..., 1.0059761 , 1.003769  ,\n",
       "        0.99790335],\n",
       "       [1.0008125 , 0.99919313, 0.9983334 , ..., 0.99993515, 0.9977591 ,\n",
       "        1.0025545 ],\n",
       "       [1.0032064 , 0.9987258 , 0.9998473 , ..., 0.9960542 , 0.99683386,\n",
       "        1.0050933 ],\n",
       "       ...,\n",
       "       [1.0017655 , 0.9974872 , 0.99775547, ..., 0.9927303 , 0.99814814,\n",
       "        1.0021478 ],\n",
       "       [1.002341  , 1.0020318 , 0.9987503 , ..., 0.9969342 , 0.99943984,\n",
       "        0.99602854],\n",
       "       [0.9972331 , 1.0007926 , 0.9999837 , ..., 1.0024247 , 1.0006697 ,\n",
       "        0.99954   ]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.distance(bigram_vector, bigram_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_words_bi_grams(string):\n",
    "    word1, words2 = string.split(' ')\n",
    "    bigram_vector = np.mean([model_gensim.wv.get_vector(word1),  model_gensim.wv.get_vector(words2)], axis=0)\n",
    "    return model_gensim.wv.similar_by_vector(bigram_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('damso', 0.9070475101470947),\n",
       " ('rappeur', 0.7939983606338501),\n",
       " ('influenceur', 0.7019269466400146),\n",
       " ('rappeu', 0.6949822306632996),\n",
       " ('musiqu', 0.6343814134597778),\n",
       " ('musique', 0.6332101225852966),\n",
       " ('qalf', 0.6330059766769409),\n",
       " ('musik', 0.6286965012550354),\n",
       " ('écouteur', 0.6198288798332214),\n",
       " ('artiste', 0.614931583404541)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_words_bi_grams('rappeur damso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this approach is performing well and we can use it to evaluate our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36174017"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similarity('saper', 'habits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are some topics that need more data related to congolese news to learn embedding from , This could be an amazing project to work on \n",
    "\n",
    "collect news articles for news papers clean them and preprocess the articles to have corrects words embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and at the end of the day create a visualizationm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('president', 0.9005034565925598),\n",
       " ('presiden', 0.8546346426010132),\n",
       " ('presidenter', 0.8443138599395752),\n",
       " ('presidente', 0.834946870803833),\n",
       " ('presidencedrc', 0.8346918225288391),\n",
       " ('presidenta', 0.8283256888389587),\n",
       " ('presidence', 0.8279198408126831),\n",
       " ('presidenc', 0.8164385557174683),\n",
       " ('preside', 0.806443452835083),\n",
       " ('presider', 0.8001581430435181)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.most_similar('president fatshi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fatshi', 0.8293508291244507),\n",
       " ('president', 0.8204025030136108),\n",
       " ('presidence', 0.799849271774292),\n",
       " ('felixtshisekedi', 0.7835581302642822),\n",
       " ('fatshist', 0.7817815542221069),\n",
       " ('presidencerdc', 0.761992871761322),\n",
       " ('félixtshisekedi', 0.7555275559425354),\n",
       " ('tshisekedirésident', 0.7542889714241028),\n",
       " ('fatshister', 0.7514024376869202),\n",
       " ('presidencedrc', 0.7507781386375427)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_words_bi_grams('president fatshi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-course-venv-v2",
   "language": "python",
   "name": "nlp-course-venv-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
